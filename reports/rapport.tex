\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[a4paper, top=2.5cm, bottom=3cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{mathpazo}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{float}

% --- Couleurs et réglages visuels ---
\definecolor{epitablue}{RGB}{0,70,140}
\definecolor{lightgray}{gray}{0.9}

\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\textit{Page \thepage\ sur \pageref{LastPage}}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\begin{document}
\linespread{1.2}

\begin{titlepage}
    \centering
    \vspace*{\fill} % --- Centrage vertical du contenu principal ---

    % --- Logos en parallèle ---
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.75\textwidth]{figures/epita.png}\\[0.3cm]
        {\small \textbf{EPITA}}\\[-0.1cm]
        {\footnotesize École d'Ingénieurs pour l'Informatique et les Techniques Avancées}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.7\textwidth]{figures/logo_SCIA-Graphes-1024x768.png}\\[0.3cm]
        {\small \textbf{Majeure SCIA-G}}\\[-0.1cm]
        {\footnotesize Sciences Cognitives, Intelligence Artificielle\\ \& Graphes}
    \end{minipage}

    % --- Ligne décorative fine ---
    \vspace{1.5cm}
    \rule{\textwidth}{0.6pt}\\[1.5cm]

    % --- Titre principal ---
    {\Huge \bfseries \textcolor{epitablue}{Projet Prédiction Conforme}}\\[0.8cm]
    {\Large \textit{Implémentation et Analyse dans le Domaine Financier}}\\[1.8cm]


    % --- Type de document ---
    {\Large \textsc{Rapport de Projet}}\\[3.5cm]

    % --- Auteurs et encadrant alignés ---
    \begin{minipage}{0.45\textwidth}
        \centering
        \textbf{Auteur}\\[0.3cm]
        \begin{tabular}{rl}
            Erwann Lesech, Étudiant
        \end{tabular}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \textbf{Encadrant}\\[0.3cm]
        \begin{tabular}{rl}
            Rémi Vaucher, PhD — Professeur
        \end{tabular}
    \end{minipage}

    \vspace*{2cm}
    \rule{0.6\textwidth}{0.4pt}\\[0.8cm]

    {\large Lyon, le 12 novembre 2025}\\[0.3cm]
    {\normalsize Présenté dans le cadre du cours \textit{Stochastiques} — Promo 2026}\\[2cm]

    
    \end{titlepage}

    \tableofcontents
    \clearpage


    \section{Introduction}

    \subsection*{Contexte et enjeux de la quantification d'incertitude}
    
    Historiquement, la \textbf{régression quantile} a constitué une première approche pour estimer des intervalles statistiques autour d’une prédiction. Elle permettait déjà de quantifier l’incertitude associée à une estimation en fournissant des bornes de confiance sur la variable cible. Avec l’émergence du machine learning, les modèles se sont complexifiés et leurs performances ont considérablement augmenté, mais la question de la fiabilité des prédictions est restée centrale.
    
    Les \textbf{modèles d’apprentissage automatique} se concentrent souvent sur la recherche de la meilleure précision possible, sans nécessairement indiquer dans quelle mesure leurs prédictions peuvent être considérées comme fiables. Or, dans des domaines critiques comme la santé, la finance ou la cybersécurité, une erreur de prédiction peut avoir des conséquences majeures. Il devient donc essentiel de mesurer non seulement la valeur prédite, mais aussi le degré d’incertitude qui l’accompagne.
    
    C'est alors que la \textbf{prédiction conforme} répond précisément à ce besoin. Elle fournit un apport mathématique pour associer à chaque prédiction une estimation de confiance, tout en garantissant statistiquement un taux d’erreur contrôlé.
    
    \subsection*{Problématique du secteur financier}
    
    Le secteur financier est un exemple typique où la prise de décision repose sur des modèles prédictifs sensibles à l’incertitude. Les prévisions de risque, les notations de crédit ou l’évaluation des performances d’entreprises reposent sur des données volatiles et complexes, souvent influencées par des facteurs externes difficiles à anticiper. Dans un tel contexte, un modèle classique fournissant une seule prédiction numérique ou catégorielle peut s’avérer insuffisant, voire trompeur.
    
    L’intégration de la prédiction conforme dans ce domaine permet de mieux maîtriser la confiance associée aux estimations, qu’il s’agisse d’évaluer \textbf{la solvabilité d’une entreprise} ou \textbf{le risque financier d’un client}.
    
    La suite de ce rapport s’appuie sur deux ensembles de données issus du domaine financier, permettant d’illustrer l’apport concret de la prédiction conforme dans des contextes réels de classification et de régression.

    \section{Tâche de régression - Risque d'un client contracteur de crédit}

    \subsection{Présentation du jeu de données et pré-traitement}

    \subsubsection*{Présentation et choix du jeu de données}
    
    Le jeu de données \textit{Financial Risk for Loan Approval}\footnote{\url{https://www.kaggle.com/datasets/lorenzozoppelletto/financial-risk-for-loan-approval}} contient 20~000 observations de demandes de crédit avec 36 variables décrivant les caractéristiques financières et personnelles des emprunteurs. La variable cible \texttt{RiskScore} représente un score de risque continu (28.8 à 84.0), rendant ce dataset particulièrement adapté aux techniques de régression quantile et de prédiction conforme.
    
    Ce dataset présente plusieurs avantages pour notre étude. Avec plus de 10~000 observations disponibles pour l'entraînement après un split train/test classique, nous disposons d'un ensemble de calibration suffisamment large pour garantir la validité statistique de la prédiction conforme. La taille du dataset assure également une estimation robuste des différents quantiles en régression quantile. Par ailleurs, l'absence de structure temporelle dans les données et l'indépendance entre les observations (chaque demande de crédit correspond à un client distinct) satisfont l'hypothèse d'échangeabilité nécessaire pour les garanties théoriques de la prédiction conforme. Enfin, le caractère synthétique du dataset élimine les contraintes de confidentialité tout en préservant des distributions réalistes de variables financières, permettant une analyse approfondie sans limitation d'accès aux données.
    
    \subsubsection*{Description détaillée des données}
    
    Le dataset comprend 20~000 observations réparties sur 36 variables, sans aucune valeur manquante. Les variables se décomposent en 29 variables numériques, 6 variables catégorielles et 1 variable temporelle (\texttt{ApplicationDate}) qui sera exclue de l'analyse.
    
    La variable cible \texttt{RiskScore} est une variable continue représentant le niveau de risque associé à chaque demande de crédit. Elle s'étend de 28.8 à 84.0 avec une moyenne de 50.8 et un écart-type de 7.8. La distribution présente une légère asymétrie à droite, avec des quartiles à Q1=46, Q2=52 et Q3=56, suggérant une concentration des scores autour de la médiane avec quelques valeurs extrêmes vers les risques élevés.
    
    Les 35 variables explicatives couvrent l'ensemble des dimensions pertinentes pour l'évaluation du risque de crédit, comme synthétisé dans le tableau ci-dessous.
    
    \begin{table}[h]
    \centering
    \small
    \begin{tabular}{|l|l|p{7cm}|}
    \hline
    \textbf{Catégorie} & \textbf{Type} & \textbf{Variables principales} \\
    \hline
    \hline
    Profil démographique & Numérique & \texttt{Age}, \texttt{Experience}, \texttt{NumberOfDependents}, \texttt{JobTenure} \\
    \cline{2-3}
    & Catégorielle & \texttt{EducationLevel}, \texttt{EmploymentStatus}, \texttt{MaritalStatus} \\
    \hline
    Revenus \& Patrimoine & Numérique & \texttt{AnnualIncome}, \texttt{MonthlyIncome}, \texttt{TotalAssets}, \texttt{NetWorth}, \texttt{SavingsAccountBalance}, \texttt{CheckingAccountBalance} \\
    \hline
    Historique de crédit & Numérique & \texttt{CreditScore}, \texttt{LengthOfCreditHistory}, \texttt{PaymentHistory}, \texttt{PreviousLoanDefaults}, \texttt{BankruptcyHistory} \\
    \hline
    Crédit en cours & Numérique & \texttt{NumberOfOpenCreditLines}, \texttt{NumberOfCreditInquiries}, \texttt{CreditCardUtilizationRate} \\
    \hline
    Dette & Numérique & \texttt{TotalLiabilities}, \texttt{MonthlyDebtPayments}, \texttt{DebtToIncomeRatio}, \texttt{TotalDebtToIncomeRatio} \\
    \hline
    Demande de prêt & Numérique & \texttt{LoanAmount}, \texttt{LoanDuration}, \texttt{MonthlyLoanPayment}, \texttt{InterestRate}, \texttt{BaseInterestRate} \\
    \cline{2-3}
    & Catégorielle & \texttt{LoanPurpose}, \texttt{HomeOwnershipStatus} \\
    \hline
    Autres & Numérique & \texttt{UtilityBillsPaymentHistory} \\
    \hline
    \end{tabular}
    \caption{Synthèse des variables du dataset de régression}
    \end{table}
    
    La variable \texttt{LoanApproved}, présente dans le dataset original, représente une décision binaire d'approbation du prêt. Cette variable étant un label alternatif (classification), elle est exclue de notre analyse de régression pour éviter toute fuite d'information et se concentrer uniquement sur la prédiction du score de risque continu.
    
    \subsubsection*{Problématique métier et justification}
    
    Considérons le scénario d'un conseiller bancaire face à une demande de crédit. Un modèle de machine learning classique lui fournirait une prédiction unique : « Ce client a un score de risque estimé à 48 ». Cette information, bien qu'utile, reste insuffisante pour prendre une décision éclairée. Le conseiller ne dispose d'aucune indication sur la fiabilité de cette prédiction. S'agit-il d'un profil typique, bien compris par le modèle, ou d'un cas atypique où l'incertitude est élevée ?
    
    La \textbf{régression quantile} enrichit cette analyse en produisant de intervalles. Si l'intervalle est étroit, le profil est bien caractérisé et une décision automatisée peut être envisagée. Si l'intervalle est large, cela signale une forte variabilité du risque et justifie un examen approfondi. Cette information permet également d'adapter les conditions du prêt : un client au quantile élevé pourrait se voir proposer un taux d'intérêt majoré ou des garanties supplémentaires.
    
    La \textbf{prédiction conforme} va plus loin en fournissant une garantie statistique : « Avec 90\% de confiance, le véritable score de risque se situe dans l'intervalle [45, 51] ». Contrairement à un modèle classique qui ne contrôle pas son taux d'erreur, la prédiction conforme garantit que 90\% des clients auront leur score réel couvert par l'intervalle prédit. Cette propriété est cruciale dans un contexte réglementaire où les institutions financières doivent justifier leurs décisions et maîtriser leur exposition au risque. Un intervalle trop large pour un client donné peut déclencher une analyse manuelle, tandis qu'un intervalle étroit valide la confiance du modèle et accélère le processus d'approbation.
        
    \subsubsection*{Analyse exploratoire des données (EDA)}
    
    L'analyse exploratoire révèle plusieurs caractéristiques importantes du dataset. La distribution de la variable cible \texttt{RiskScore} présente une légère asymétrie à droite avec quelques valeurs aberrantes au-delà de 70, suggérant l'existence de profils à très haut risque peu fréquents mais à surveiller (Figure~\ref{fig:eda_riskscore_dist}).
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/distribution_cible_regression.png}
        \caption{Distribution de la variable cible RiskScore (histogramme et boxplot)}
        \label{fig:eda_riskscore_dist}
    \end{figure}
    
    L'analyse de corrélation met en évidence plusieurs variables fortement liées entre elles. Les variables \texttt{MonthlyIncome} et \texttt{AnnualIncome} affichent logiquement une corrélation très élevée (0.99), tout comme \texttt{Age} et \texttt{Experience} (0.983). L'analyse bivariée (Figure~\ref{fig:eda_bivariate}) révèle une variable visuellement très corrélée à la cible : \texttt{MonthlyIncome}. Cela semble logique côté métier, le premier critère d'évaluation du risque étant la capacité de remboursement liée aux revenus. Nous risquons donc d'utiliser cette variable comme exemple pour notre régression quantile plus tard.
    
    \begin{figure}[H]
        \centering
        \begin{minipage}[b]{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/matrice_corr_regression.png}
            \caption{Matrice de corrélation des variables numériques}
            \label{fig:eda_corr_matrix}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/regression_most_correlated_bivariee.png}
            \caption{Analyse bivariée : relations entre features principales et RiskScore}
            \label{fig:eda_bivariate}
        \end{minipage}
    \end{figure}
    
    \begin{minipage}[t]{0.55\textwidth}
        \vspace{0pt}
        Enfin, le graphique des corrélations avec la cible (Figure~\ref{fig:eda_feature_importance}) permet d'identifier les variables les plus prédictives. Hormis \texttt{LoanApproved} qui est exclue de l'analyse, on retrouve à nouveau la variable \texttt{MonthlyIncome} (-0.487), ainsi que \texttt{AnnualIncome} (-0.483) et \texttt{BankruptcyHistory} (0.378) comme les features les plus corrélées à \texttt{RiskScore}.
    \end{minipage}%
    \hfill%
    \begin{minipage}[t]{0.42\textwidth}
        \vspace{0pt}
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.7\textwidth]{figures/matrice_corr_cible_regression.png}
            \caption{Corrélations des features avec la variable cible RiskScore}
            \label{fig:eda_feature_importance}
        \end{figure}
    \end{minipage}
    
    \subsubsection*{Préparation et prétraitement des données}
    
    Le prétraitement des données s'effectue en plusieurs étapes successives. La variable \texttt{ApplicationDate}, représentant une série temporelle synthétique sans valeur prédictive, est d'abord supprimée. De même, la variable \texttt{LoanApproved}, qui correspond à un label binaire d'approbation de prêt et constitue donc une tâche de classification alternative, est exclue de l'analyse pour se concentrer uniquement sur la prédiction du score de risque continu.
    
    Les variables catégorielles (\texttt{EmploymentStatus}, \texttt{EducationLevel}, \texttt{MaritalStatus}, \texttt{LoanPurpose}, \texttt{HomeOwnershipStatus}) sont ensuite encodées en utilisant un encodage one-hot, créant des variables binaires pour chaque modalité tout en supprimant une modalité de référence pour éviter la multicolinéarité. Les variables numériques sont normalisées par standardisation (moyenne 0, écart-type 1) afin d'homogénéiser les échelles et d'améliorer la convergence des algorithmes d'apprentissage.

    \newpage

    \section{Régression Quantile}
    
    \subsection{Fondements théoriques}
    
    La régression quantile modélise les quantiles conditionnels de la variable cible plutôt que sa moyenne. Pour un quantile $\tau \in (0,1)$, elle résout :
    
    $$\hat{\beta}_\tau = \arg\min_{\beta} \sum_{i=1}^n \rho_\tau(y_i - x_i^T\beta)$$
    
    où $\rho_\tau(u)$ est la fonction de perte quantile (pinball loss) définie par :
    
    $$\rho_\tau(u) = u(\tau - \mathbf{1}_{u < 0}) = \begin{cases} 
    \tau u & \text{si } u \geq 0 \\
    (\tau - 1) u & \text{si } u < 0
    \end{cases}$$
        
    \subsection{Choix du modèle et justification}
    
    Nous avons implémenté une régression quantile linéaire via \texttt{QuantileRegressor} de scikit-learn.
    
    Trois configurations ont été testées : (1) une seule feature (\texttt{MonthlyIncome}), permettant une visualisation 2D, (2) toutes les features disponibles (33 après preprocessing), (3) les features fortement corrélées ($|$corr$|$ $\geq$ 0.3). Une quatrième configuration ajoute une \textbf{extension polynomiale de degré 2} au modèle 1 pour vérifier l'existence de non-linéarités quadratiques entre le revenu et le risque.
    
    \subsection{Mise en place et construction des intervalles}
    
    Le prétraitement suit le protocole établi : encodage one-hot des catégorielles et standardisation des numériques. Le split train/test (67\%/33\%) garantit une évaluation robuste sur 6~600 observations.
    
    Pour un niveau de confiance $1-\beta = 90\%$ ($\beta=0.1$), trois régressions quantiles sont entraînées par configuration : $Q_{0.05}$ (borne inférieure), $Q_{0.50}$ (médiane conditionnelle) et $Q_{0.95}$ (borne supérieure). L'intervalle de prédiction est construit comme $[Q_{0.05}(X_{new}), Q_{0.95}(X_{new})]$, devant théoriquement contenir 90\% des observations.
    
    \subsection{Résultats et interprétation}
    
    \subsubsection*{Métriques de performance \& résultats}
    
    Le \textbf{taux de couverture empirique} mesure la calibration du modèle :
    
    $$\text{Coverage} = \frac{1}{n_{test}} \sum_{i=1}^{n_{test}} \mathbb{1}_{Q_{0.05}(X_i) \leq y_i \leq Q_{0.95}(X_i)}$$
    
    Un modèle bien calibré doit afficher un taux proche de 90\%. Une procédure de bootstrap de 50 itérations permet d'assurer la stabilité de cette mesure au dépend de l'aléatoire.
    

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\textwidth]{figures/quantile_reg_coverages.png}
        \caption{Taux de couverture empirique des quatre modèles de régression quantile}
        \label{fig:quantile_coverage}
    \end{figure}

    D'autres métriques comme la \texttt{RMSE} ou la \texttt{MAE} ont été utilisé pour comparer la précision des modèles (basé seulement sur le quantile médian). Enfin la largeur moyenne des intervalles ont aussi été mesurés comme montré ci-contre:

    \begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|c|c|c|c|}
    \hline
    \textbf{Modèle} & \textbf{MAE} & \textbf{RMSE} & \textbf{Coverage (\%)} & \textbf{Largeur moy.} \\
    \hline
    \hline
    Modèle 1 (1 feature linéaire) & 5.29 & 6.84 & 89.44 $\pm$ 0.37 & 22.32 \\
    \hline
    Modèle 2 (toutes features) & \textbf{2.77} & \textbf{3.88} & 89.12 $\pm$ 0.36 & \textbf{10.89} \\
    \hline
    Modèle 3 (features corrélées) & 3.84 & 5.14 & \textbf{89.82 $\pm$ 0.37} & 16.38 \\
    \hline
    Modèle 4 (1 feature polynomiale) & 5.23 & 6.75 & 89.26 $\pm$ 0.35 & 22.25 \\
    \hline
    \end{tabular}
    \caption{Comparaison des performances des modèles de régression quantile}
    \end{table}

    
    \subsubsection*{Analyse comparative}
    
    Le \textbf{modèle 2} (toutes features) offre la meilleure précision prédictive (MAE=2.77, RMSE=3.88) avec les intervalles les plus étroits (10.89 points), confirmant l'apport d'une information multivariée complète. Sa couverture légèrement inférieure (89.12\%) suggère néanmoins des difficultés sur certains profils atypiques.
    
    Le \textbf{modèle 3} (features corrélées) constitue le meilleur compromis : couverture optimale (89.82\%), précision intermédiaire (MAE=3.84) et largeur raisonnable (16.38 points). Il démontre qu'une sélection rigoureuse de variables ($|$corr$|$ $\geq$ 0.3) suffit à capturer l'essentiel de l'information prédictive.
    
    Les \textbf{modèles 1 et 4} (linéaire vs polynomial) présentent des performances quasi-identiques. L'amélioration marginale du modèle polynomial (MAE 5.23 vs 5.29) valide que la relation \texttt{MonthlyIncome}--\texttt{RiskScore} est \textbf{essentiellement linéaire}, avec peu de non-linéarité quadratique à exploiter.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{figures/comparaison_quantile_reg_mod_1.png}
        \caption{Régression quantile sur le modèle 1 (une seule feature) : quantiles 0.05, 0.50 et 0.95}
        \label{fig:quantile_reg_model1}
    \end{figure}

    Tous les modèles affichent une couverture proche de 90\% avec une faible variabilité ($\pm$ 0.35-0.37\%), démontrant la fiabilité de la régression quantile pour construire des intervalles bien calibrés.
    
    \subsubsection*{Plus-value métier}
    
    La régression quantile fournit une information cruciale pour la décision de crédit en produisant trois scénarios : (1) \textbf{optimiste} ($Q_{0.05}$) pour le pricing agressif, (2) \textbf{central} ($Q_{0.50}$) pour la décision standard, (3) \textbf{pessimiste} ($Q_{0.95}$) pour l'évaluation du risque maximal.
    
    Un conseiller bancaire peut adapter les conditions du prêt selon la largeur de l'intervalle. Un intervalle étroit signale une prédiction fiable autorisant une décision automatisée, tandis qu'un intervalle large indique une forte incertitude justifiant un examen manuel approfondi. Le choix du modèle dépend du contexte opérationnel : modèle 1 pour l'interprétabilité maximale et la communication client, modèle 3 pour l'équilibre précision/simplicité, modèle 2 pour la performance maximale en production.
    
    \section{Prédiction Conforme pour la Régression}
    
    \subsection{Choix des méthodes et justification}
    
    Nous avons implémenté deux variantes de prédiction conforme pour la régression, chacune adaptée à des contextes différents.
    
    \subsubsection*{Split Conformal Prediction (SCP)}
    
    SCP est la méthode la plus simple et directe. Elle divise les données en trois ensembles disjoints : train (50\%), calibration (40\%) et test (10\%). Le modèle est entraîné une fois sur le train set, puis calibré sur le calibration set pour calculer le quantile $\hat{q}$ des scores de non-conformité. Cette approche est efficace avec des datasets volumineux (> 10~000 obs.) car le split ne réduit pas significativement la taille effective. Son avantage est sa rapidité (un seul entraînement) et sa simplicité d'implémentation.
    
    \subsubsection*{Cross-Validation Plus (CV+)}
    
    CV+ exploite mieux les données via validation croisée K-folds. Elle entraîne $K$ modèles (ici $K=3$) sur des folds différents et collecte les scores de non-conformité sur les prédictions out-of-sample de chaque fold. Le quantile est calculé sur l'ensemble agrégé de ces scores. Pour la prédiction finale, les $K$ modèles sont moyennés, réduisant la variance. Cette approche est plus robuste sur datasets moyens (2~000–10~000 obs.) en exploitant mieux les données disponibles, au prix d'un coût $K$ fois supérieur.
    
    \subsubsection*{Pourquoi pas Jackknife+ et Full Conformal Prediction ?}
    
    \textbf{Jackknife+} nécessite $n$ entraînements en leave-one-out (20~000 sur notre dataset), soit un coût prohibitif sans gain pratique significatif.
    
    \textbf{Full Conformal Prediction (FCP)} requiert de tester toutes les valeurs candidates $y_{new}$ en réentraînant le modèle à chaque fois, rendant la méthode inapplicable en production.
    
    \textbf{SCP} et \textbf{CV+} offrent le meilleur compromis rigueur/applicabilité pour l'évaluation du risque de crédit.
    
    \subsection{Mise en place des modèles}
    
    \subsubsection*{Division des données et prétraitement}
    
    Le preprocessing suit le protocole standard : encodage one-hot des catégorielles et standardisation des numériques. Pour SCP, split en trois ensembles disjoints : train (50\%, 10~000 obs.), calibration (40\%, 8~000 obs.) et test (10\%, 2~000 obs.). Pour CV+, fusion train+calibration (90\%, 18~000 obs.) utilisée pour validation croisée 3-folds, avec test set identique pour comparaison équitable.
    
    \subsubsection*{Choix de l'algorithme ML de base}
    
    Nous avons utilisé une \textbf{régression Ridge} (\texttt{Ridge}, $\alpha=1.0$) comme modèle de base $\hat{f}$. Ridge offre stabilité via régularisation L2, évitant le surapprentissage tout en restant interprétable. Sa rapidité d'entraînement est cruciale pour CV+. Des modèles plus complexes (\texttt{RandomForest}, \texttt{GradientBoosting}) auraient de meilleures performances mais un temps d'entraînement trop long pour cette étude.
        
    \subsubsection*{Principe commun : score de conformité}
    
    Les deux méthodes partagent la même logique fondamentale. Le \textbf{score de conformité} mesure l'écart entre prédiction et valeur réelle :
    
    $$S(X_i, y_i) = |y_i - \hat{f}(X_i)|$$
    
    Nous utilisons l'erreur absolue (L1), symétrique et robuste aux outliers. Sur l'ensemble de calibration (ou via CV), on calcule les scores $S_1, \ldots, S_n$ et leur quantile ajusté :
    
    $$\hat{q} = \text{Quantile}\left(S_1, \ldots, S_n; \frac{\lceil (n+1)(1-\alpha) \rceil}{n}\right)$$
    
    L'intervalle de prédiction pour $X_{new}$ est :
    
    $$\hat{C}(X_{new}) = [\hat{f}(X_{new}) - \hat{q}, \; \hat{f}(X_{new}) + \hat{q}]$$
    
    \subsection{Résultats et interprétation}
    
    \subsubsection*{Synthèse des performances}
    
    Sur le test set (2~000 observations), les deux méthodes respectent la garantie théorique de 90\% de couverture :
    
    \begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|c|c|c|c|}
    \hline
    \textbf{Méthode} & \textbf{Couverture} & \textbf{Largeur moy.} & \textbf{MAE} & \textbf{R²} \\
    \hline
    \hline
    SCP & 89.15\% & 11.85 & 3.94 & 0.785 \\
    \hline
    CV+ & \textbf{90.20\%} & \textbf{6.16} & \textbf{2.89} & \textbf{0.940} \\
    \hline
    \end{tabular}
    \caption{Comparaison SCP vs CV+ pour la prédiction conforme en régression}
    \end{table}
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{figures/pred_conform_regression_results.png}
        \caption{Exemples de prédictions avec intervalles conformes pour SCP et CV+ sur le test set}
        \label{fig:pred_conforme_regression_examples}
    \end{figure}
    
    \textbf{CV+ surpasse SCP} sur tous les critères : couverture optimale (90.20\% vs 89.15\%), intervalles 48\% plus étroits (6.16 vs 11.85), et meilleures performances prédictives (R²=0.940 vs 0.785). L'exploitation de la validation croisée permet à CV+ d'utiliser 18~000 observations au lieu de 10~000 pour SCP, expliquant ces améliorations. Pourtant, la SCP présente déjà des résultats probants.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{figures/pred_conform_regression_cover.png}
        \caption{Comparaison des taux de couverture et largeurs moyennes d'intervalles pour SCP et CV+}
        \label{fig:pred_conforme_regression_comparison}
    \end{figure}
    
    \subsubsection*{Intérêt métier}

    À l'instar de la régression quantile, la prédiction conforme fournit non pas une valeur ponctuelle mais un intervalle prédictif contenant la valeur réelle avec une probabilité garantie de \(90\%\). Pour une banque, cela se traduit par :

    \begin{itemize}
    \item décision automatisée si le score et son intervalle restent en-deçà d'un seuil de risque interne ;
    \item analyse approfondie si l'intervalle est large ou chevauche des zones à risque ;
    \item rejet si l'intervalle dépasse les niveaux tolérés.
    \end{itemize}

    De plus, la largeur et la position de l'intervalle permettent d'ajuster les \emph{conditions de prêt} (taux, garanties, plafond) : un intervalle favorable peut améliorer l'offre, un intervalle défavorable ou incertain justifie des conditions plus strictes.

    \subsubsection*{Limites et perspectives}

    Les intervalles construits ici sont symétriques et de largeur constante, ce qui ne capte pas l'hétérogénéité de l'incertitude par profil. Une amélioration est l'utilisation de la \textbf{Conformal Quantile Regression (CQR)} pour obtenir des intervalles adaptatifs et asymétriques tout en conservant des garanties conformes.

    Dans notre cas d'étude, l'implémentation de CQR a été tentée mais freinée par une capacité mémoire insuffisante : la réduction du volume de données pour l'entraînement a dégradé la qualité des résultats. Il conviendrait donc de réessayer CQR avec une machine plus performante pour valider son bénéfice.

    \section{Tâche de classification - Catégorie de note de crédit d'entreprise}
    \subsection{Présentation du jeu de données et pré-traitement}
    
    \subsubsection*{Présentation et choix du jeu de données}
    
    Le jeu de données \textit{Corporate Credit Rating}\footnote{\url{https://www.kaggle.com/datasets/agewerc/corporate-credit-rating}} contient 2~031 observations de notations de crédit d'entreprises américaines avec 31 variables décrivant leurs performances financières et opérationnelles. La variable cible \texttt{Rating} représente une notation de crédit catégorielle (10 classes : AAA, AA, A, BBB, BB, B, CCC, CC, C, D), rendant ce dataset particulièrement adapté aux techniques de prédiction conforme pour la classification.
    
    Ce dataset présente plusieurs avantages pour notre étude. Bien que plus petit que le dataset de régression, il offre suffisamment d'observations pour garantir la validité statistique de la prédiction conforme après calibration (> 1000 données) et peut nous permettre éventuellement d'essayer d'appliquer des algorithmes permettant un ensemble de calibration réduit. La présence de notations issues de quatre agences de notation réputées (Standard \& Poor's, Moody's, Fitch Ratings, Egan-Jones) assure la crédibilité et la cohérence des labels. L'absence de structure temporelle dans les données et l'indépendance entre les observations (chaque notation correspond à une entreprise à un instant donné) satisfont l'hypothèse d'échangeabilité requise pour les garanties théoriques de la prédiction conforme. Enfin, le dataset couvre 25 secteurs d'activité différents, offrant une diversité sectorielle représentative du tissu économique américain.
    
    \subsubsection*{Description détaillée des données}
    
    Le dataset comprend 2~031 observations réparties sur 31 variables, sans aucune valeur manquante. Les variables se décomposent en 28 variables numériques (ratios financiers), 2 variables catégorielles (\texttt{Sector}, \texttt{Rating Agency Name}) et 3 variables d'identification (\texttt{Name}, \texttt{Symbol}, \texttt{Date}) qui seront exclues de l'analyse.
    
    La variable cible \texttt{Rating} est une variable catégorielle ordinale représentant la notation de crédit de l'entreprise selon l'échelle traditionnelle. Elle comporte 10 classes allant de AAA (meilleure qualité de crédit) à D (défaut de paiement). La distribution initiale présente un déséquilibre important, avec une forte concentration sur les classes A (671 observations, 33.0\%) et BBB (624 observations, 30.7\%), tandis que certaines classes sont gravement sous-représentées : D (1 observation), C (2 observations), CC (8 observations) et AAA (52 observations). Ce déséquilibre, avec un ratio maximum/minimum de 671:1, nécessite un regroupement des classes pour garantir la robustesse des modèles.
    
    Les 28 variables explicatives numériques couvrent l'ensemble des dimensions pertinentes pour l'évaluation du risque de crédit d'entreprise, comme synthétisé dans le tableau ci-dessous.
    
    \begin{table}[h]
    \centering
    \small
    \begin{tabular}{|l|p{8cm}|}
    \hline
    \textbf{Catégorie} & \textbf{Variables principales} \\
    \hline
    \hline
    Liquidité & \texttt{currentRatio}, \texttt{quickRatio}, \texttt{cashRatio}, \texttt{cashPerShare} \\
    \hline
    Rentabilité & \texttt{netProfitMargin}, \texttt{returnOnAssets}, \texttt{returnOnEquity}, \texttt{returnOnCapitalEmployed}, \texttt{operatingProfitMargin}, \texttt{grossProfitMargin}, \texttt{pretaxProfitMargin}, \texttt{ebitPerRevenue} \\
    \hline
    Efficacité opérationnelle & \texttt{assetTurnover}, \texttt{fixedAssetTurnover}, \texttt{daysOfSalesOutstanding}, \texttt{payablesTurnover} \\
    \hline
    Structure financière & \texttt{debtEquityRatio}, \texttt{debtRatio}, \texttt{companyEquityMultiplier} \\
    \hline
    Flux de trésorerie & \texttt{freeCashFlowPerShare}, \texttt{operatingCashFlowPerShare}, \texttt{freeCashFlowOperatingCashFlowRatio}, \texttt{operatingCashFlowSalesRatio} \\
    \hline
    Fiscalité \& Valorisation & \texttt{effectiveTaxRate}, \texttt{enterpriseValueMultiple} \\
    \hline
    \end{tabular}
    \caption{Synthèse des variables du dataset de classification}
    \end{table}
    
    Les deux variables catégorielles complémentaires sont \texttt{Sector} (25 secteurs : Technology, Health Care, Consumer Durables, etc.) et \texttt{Rating Agency Name} (4 agences : Standard \& Poor's, Moody's, Fitch Ratings, Egan-Jones).
    
    \subsubsection*{Problématique métier et justification}
    
    Considérons le scénario d'un analyste financier chargé d'évaluer le risque de crédit d'une entreprise pour décider d'un investissement obligataire. Un modèle de classification classique lui fournirait une prédiction unique : « Cette entreprise est notée BBB ». Cette information, bien qu'utile, reste insuffisante pour une prise de décision éclairée. L'analyste ne dispose d'aucune indication sur la confiance du modèle dans cette prédiction. S'agit-il d'un profil clairement BBB, ou l'entreprise se situe-t-elle à la frontière entre Investment Grade et Speculative Grade ?
    
    La \textbf{prédiction conforme pour la classification} enrichit radicalement cette analyse en produisant des \textbf{ensembles de prédiction}. Au lieu d'une classe unique, le modèle pourrait indiquer : « Avec 90\% de confiance, cette entreprise appartient à l'ensemble \{BBB, BB\} ». Cette information est beaucoup plus riche pour la décision. Un ensemble contenant uniquement BBB signale une prédiction très confiante et permet une décision rapide. Un ensemble \{BBB, BB\} indique une entreprise à la frontière Investment Grade/Speculative, justifiant une analyse approfondie. Un ensemble large \{A, BBB, BB\} révèle une forte incertitude et nécessite une due diligence complète avant investissement.
    
    Dans le contexte réglementaire bancaire, cette approche est particulièrement pertinente. Les accords de Bâle imposent des exigences de fonds propres différentes selon la catégorie de crédit. Une entreprise classée Investment Grade (AAA à BBB) bénéficie de conditions favorables, tandis qu'une notation Speculative Grade (BB et inférieur) entraîne des exigences accrues. La prédiction conforme offre donc une garantie statistique contrôlée : sur 100 prédictions avec un niveau de confiance de 90\%, au moins 90 contiendront la vraie classe. Cette propriété est cruciale pour justifier les décisions d'investissement auprès des régulateurs et des comités de risque.
    
    De plus, le regroupement des classes en 6 catégories cohérentes (IG\_HIGH, IG\_MED, IG\_LOW pour Investment Grade ; SPEC\_HIGH, SPEC\_MED, SPEC\_LOW pour Speculative Grade) aligne parfaitement l'approche technique avec les pratiques métier, où la distinction majeure se fait entre obligations investissables et spécu\-latives.
    
    \subsubsection*{Analyse exploratoire des données (EDA)}
    
    L'analyse exploratoire révèle plusieurs caractéristiques importantes du dataset. La distribution initiale de la variable cible \texttt{Rating} présente un déséquilibre critique, avec une concentration massive sur les classes A (33.0\%) et BBB (30.7\%), représentant ensemble près de 64\% des observations. À l'opposé, les classes extrêmes sont gravement sous-représentées : D (1 obs.), C (2 obs.), CC (8 obs.) et AAA (52 obs.), rendant impossible un apprentissage robuste sur ces catégories (Figure~\ref{fig:eda_rating_dist}).
    
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/classif_cible_distrib.png}
        \caption{Distribution originale de la variable cible Rating (10 classes fortement déséquilibrées)}
        \label{fig:eda_rating_dist}
    \end{figure}
    
    Pour remédier à ce déséquilibre, nous avons procédé à un regroupement des classes en 6 catégories basées sur la distinction Investment Grade / Speculative Grade, reflétant les pratiques financières réelles (Figure~\ref{fig:eda_grouped_rating}). Cette transformation améliore considérablement l'équilibre du dataset, avec un ratio maximum/minimum passant de 671:1 à seulement 9.3:1, et une classe minimale passant de 1 à 72 observations.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/classif_cible_distrib_new.png}
        \caption{Distribution regroupée de la variable cible (6 classes équilibrées)}
        \label{fig:eda_grouped_rating}
    \end{figure}
    
    L'analyse de corrélation met en évidence plusieurs variables numériques fortement corrélées entre elles. Les indicateurs de rentabilité (\texttt{returnOnAssets}, \texttt{returnOnEquity},\\ \texttt{returnOnCapitalEmployed}) présentent des corrélations élevées entre eux indiquant que de futurs travaux pourraient envisager d'éliminer certaines redondances (Figure~\ref{fig:eda_corr_matrix_classif}).
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\textwidth]{figures/classif_corr.png}
        \caption{Matrice de corrélation des variables numériques}
        \label{fig:eda_corr_matrix_classif}
    \end{figure}

    Enfin, l'analyse de corrélation entre les variables numériques et la classe regroupée encodée (Figure~\ref{fig:eda_feature_corr_classif}) révèle que \texttt{debtRatio} (+0.22), \texttt{enterpriseValueMultiple} (+0.086) et \texttt{cashRatio} (+0.025) sont positivement corrélés avec un meilleur rating, tandis que les indicateurs \texttt{payables\-Turnover} (-0.06) et \texttt{freeCashFlow\-Operating\-CashFlow\-Ratio} (-0.052) montrent une corrélation négative. Toutefois, ces corrélations restent faibles, suggérant que la prédiction de la notation de crédit nécessite une analyse multivariée complexe plutôt qu'une simple relation linéaire avec une ou deux variables.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{figures/matrice_corr_cible_classif.png}
        \caption{Corrélations des features avec la variable cible Grouped\_Rating}
        \label{fig:eda_feature_corr_classif}
    \end{figure}
    
    \subsubsection*{Préparation et prétraitement des données}
    
    Le prétraitement des données s'effectue en plusieurs étapes successives. Les variables d'identification (\texttt{Name}, \texttt{Symbol}, \texttt{Date}), ne contenant que des informations nominatives ou temporelles sans valeur prédictive, sont d'abord supprimées du dataset.
    
    La variable cible \texttt{Rating} fait l'objet d'un regroupement en 6 classes hiérarchiques pour résoudre le problème de déséquilibre critique :
    
    \begin{itemize}
        \item \textbf{IG\_HIGH} (Investment Grade - Haute qualité) : AAA, AA
        \item \textbf{IG\_MED} (Investment Grade - Qualité moyenne) : A
        \item \textbf{IG\_LOW} (Investment Grade - Qualité satisfaisante) : BBB
        \item \textbf{SPEC\_HIGH} (Speculative Grade - Modérément spéculatif) : BB
        \item \textbf{SPEC\_MED} (Speculative Grade - Spéculatif) : B
        \item \textbf{SPEC\_LOW} (Speculative Grade - Très spéculatif/Défaut) : CCC, CC, C, D
    \end{itemize}
    
    Ce regroupement s'aligne sur les pratiques financières réelles où la frontière majeure se situe entre Investment Grade (BBB et supérieur) et Speculative Grade (BB et inférieur), tout en préservant une granularité suffisante pour distinguer les niveaux de risque au sein de chaque catégorie.
    
    Les variables catégorielles (\texttt{Sector}, \texttt{Rating Agency Name}) sont ensuite encodées en utilisant un encodage one-hot, créant des variables binaires pour chaque modalité tout en supprimant une modalité de référence pour éviter la multicolinéarité. Les variables numériques sont normalisées par standardisation.

    \section{Prédiction Conforme pour la Classification}
    
    \subsection{Choix des méthodes et justification}
    
    Nous avons implémenté deux approches de prédiction conforme pour la classification, chacune adaptée à un contexte spécifique.
    
    \subsubsection*{Split Conformal Prediction (SCP)}
    
    Présenté précédemment pour la prédiction conforme en régression, SCP divise les données en trois ensembles disjoints : train, calibration et test. Cette méthode est simple et rapide, adaptée aux datasets volumineux, \textbf{ce qui n'est pas le cas ici}. Cela risque de limiter la taille effective du calibration set, impactant la précision des ensembles de prédiction.
    
    Nous aurions voulu utiliser d'autres algorithmes vu en cours comme Jackknife+ ou CV+ pour leur meilleure exploitation d'un faible quantité de données, cependant ils ne semblent pas applicable en classification. C'est pourquoi après quelques recherches, nous nous sommes rabattus sur la Cross-Conformal Prediction (CCP) comme seconde méthode.
    
    \subsubsection*{Cross-Conformal Prediction (CCP)}
    
    CCP exploite la validation croisée K-folds pour maximiser l'utilisation des données disponibles. La méthode a été entièrement implémentée par LLM en s'appuyant sur le papier fondateur de Lei et al.~\cite{lei2014distributionfreepredictiveinferenceregression}. Elle entraîne $K$ modèles (ici $K=5$) et combine leurs p-values via moyenne arithmétique pour garantir la validité statistique. Cette implémentation sert de référence pour évaluer les limites de notre SCP face à un dataset de taille modeste. 
    
    \textbf{Note importante} : CCP ne rentre pas dans les critères de notation du projet car entièrement générée par IA. Elle constitue uniquement un outil de comparaison pour comprendre l'impact de la taille du calibration set sur les performances de SCP.
    
    \subsubsection*{Choix des scores de conformité}
    
    Deux scores ont été testés pour mesurer la non-conformité d'une prédiction :
    
    \textbf{Score absolu} : $S(X, y) = 1 - \hat{p}(y|X)$ où $\hat{p}(y|X)$ est la probabilité prédite pour la classe $y$. Simple et interprétable, il pénalise directement les classes avec faible probabilité.
    
    \textbf{Score cumulatif} : $S(X, y) = \sum_{j : \hat{p}(j|X) \geq \hat{p}(y|X)} \hat{p}(j|X)$. Ce score mesure la masse de probabilité cumulée jusqu'à la vraie classe (classement décroissant). Il tend à produire des ensembles plus larges mais mieux calibrés sur les classes difficiles.
    
    \subsection{Mise en place des modèles}
    
    \subsubsection*{Division des données et prétraitement}
    
    Le preprocessing suit le protocole établi lors de la section précédente. Pour la SCP, split en train (1~219 obs., 60\%), calibration (609 obs., 30\%) et test (203 obs., 10\%). Pour la CCP, fusion du jeu de train et du jeu de calibration (1~828 obs., 90\%) avec validation croisée 5-folds, test set identique pour les deux méthodes.
    
    \subsubsection*{Choix de l'algorithme ML de base}
    
    Nous avons utilisé un \textbf{RandomForestClassifier} optimisé par GridSearch sur 3-fold CV. Les hyperparamètres testés incluent \texttt{n\_estimators} $\in$ \{100, 200, 300\}, \texttt{max\_depth} $\in$ \{5, 8, 10\}, \texttt{min\_samples\_split} $\in$ \{5, 10\}, et \texttt{class\_weight} $\in$ \{balanced, balanced\_subsample\}. Malgré cela, la taille du dataset et la complexité du problème ont limité la précision du meilleure modèle à environ 49\% d'exactitude sur le test set. Nous avons pu tester une autre grid search sur un \texttt{XGBClassifier} mais le gain de performance n'était pas significatif.
    
    \subsubsection*{Principe de la prédiction conforme en classification}
    
    Pour SCP, on calcule les scores de conformité $S_i = S(X_i, y_i)$ sur le calibration set, puis le quantile ajusté :
    
    $$\hat{q} = \text{Quantile}\left(S_1, \ldots, S_n; \frac{\lceil (n+1)(1-\alpha) \rceil}{n}\right)$$
    
    L'ensemble de prédiction pour $X_{new}$ inclut toutes les classes $y$ telles que $S(X_{new}, y) \leq \hat{q}$ :
    
    $$\hat{C}(X_{new}) = \{y : S(X_{new}, y) \leq \hat{q}\}$$
    
    Pour CCP, la procédure est similaire mais utilise des p-values calculées par fold et combinées par moyenne arithmétique. L'ensemble contient les classes dont la p-value moyenne dépasse $\alpha$.
    
    \subsection{Résultats et interprétation}
    
    \subsubsection*{Synthèse des performances}
    
    Sur le test set (203 observations), les quatre configurations testées donnent les résultats suivants :
    
    \begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|c|c|}
    \hline
    \textbf{Méthode} & \textbf{Couverture} & \textbf{Taille moyenne} \\
    \hline
    \hline
    SCP (score absolu) & 87.68\% & 2.65 \\
    \hline
    SCP (score cumulatif) & 85.71\% & 2.70 \\
    \hline
    CCP (score absolu) & 89.16\% & 2.67 \\
    \hline
    CCP (score cumulatif) & \textbf{91.63\%} & \textbf{2.86} \\
    \hline
    \end{tabular}
    \caption{Comparaison des méthodes de prédiction conforme en classification}
    \end{table}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=1\textwidth]{figures/pred_conform_classification.png}
        \caption{Comparaison des taux de couverture et tailles moyennes d'ensembles pour les quatre configurations}
        \label{fig:pred_conforme_classification_comparison}
    \end{figure}
    
    \textbf{CCP cumulatif obtient la meilleure couverture} (91.63\%), proche de la cible théorique de 90\%, avec des ensembles de taille moyenne 2.86. Les quatre méthodes présentent des tailles d'ensembles similaires (2.65 à 2.86), indiquant une difficulté comparable à discriminer les classes de rating. Le score cumulatif de CCP surpasse légèrement le score absolu (+2.5 points de couverture), tandis que pour SCP les deux scores donnent des résultats proches en couverture mais le score cumulatif produit des ensembles légèrement plus larges.
    
    \subsubsection*{Exemples de prédictions}
    
    Le tableau ci-dessous illustre les ensembles de prédiction obtenus sur un échantillon aléatoire de 10 observations du test set. Pour chaque observation, on compare les ensembles produits par SCP avec score absolu et score cumulatif.
    
    \begin{table}[h]
    \centering
    \small
    \begin{tabular}{|c|c|p{4.5cm}|p{4.5cm}|}
    \hline
    \textbf{Obs} & \textbf{Vraie classe} & \textbf{SCP Absolu} & \textbf{SCP Cumulatif} \\
    \hline
    \hline
    15 & IG\_LOW & IG\_LOW, SPEC\_HIGH, SPEC\_MED & IG\_LOW, SPEC\_HIGH, SPEC\_MED \\
    \hline
    9 & IG\_LOW & IG\_HIGH, IG\_LOW, IG\_MED & IG\_HIGH, IG\_LOW, IG\_MED \\
    \hline
    115 & IG\_MED & IG\_HIGH, IG\_MED & IG\_HIGH, IG\_MED \\
    \hline
    78 & SPEC\_MED & SPEC\_HIGH, SPEC\_MED & IG\_LOW, SPEC\_HIGH, SPEC\_LOW, SPEC\_MED \\
    \hline
    66 & IG\_MED & IG\_LOW, IG\_MED & IG\_LOW, IG\_MED, SPEC\_HIGH \\
    \hline
    45 & SPEC\_HIGH & IG\_LOW, IG\_MED, SPEC\_HIGH & IG\_LOW, IG\_MED, SPEC\_HIGH \\
    \hline
    143 & IG\_MED & IG\_LOW, IG\_MED & IG\_LOW, IG\_MED, SPEC\_HIGH \\
    \hline
    177 & SPEC\_HIGH & IG\_LOW, IG\_MED, SPEC\_HIGH & IG\_LOW, IG\_MED, SPEC\_HIGH \\
    \hline
    200 & IG\_LOW & IG\_LOW, IG\_MED, SPEC\_HIGH & IG\_LOW, IG\_MED, SPEC\_HIGH \\
    \hline
    180 & IG\_LOW & IG\_LOW, IG\_MED, SPEC\_HIGH & IG\_LOW, IG\_MED, SPEC\_HIGH \\
    \hline
    \end{tabular}
    \caption{Exemples d'ensembles de prédiction pour SCP avec les deux scores}
    \label{tab:pred_conforme_classification_examples}
    \end{table}
    
    On observe que les deux scores produisent souvent des ensembles identiques ou très similaires. La vraie classe est systématiquement incluse dans l'ensemble (garantie de couverture respectée localement pour ces exemples). Les ensembles contiennent généralement 2 à 3 classes, reflétant la difficulté de discrimination du modèle. L'observation 78 illustre un cas où le score cumulatif produit un ensemble plus large (4 classes) que le score absolu (2 classes), révélant une incertitude accrue pour ce profil particulier.
    
    \textbf{Limite observée} : Les couvertures de SCP (87.68\% et 85.71\%) restent relativement loin de la cible théorique de 90\%, reflétant la difficulté du problème de classification à 6 classes avec un dataset de taille modeste.
    
    \subsubsection*{Analyse par classe}
    
    L'analyse du taux de couverture par classe révèle des disparités importantes. Les classes IG\_MED (A) et IG\_LOW (BBB), majoritaires dans le dataset (671 et 624 obs. originales), affichent des couvertures supérieures à 90\% avec SCP absolu. À l'inverse, les classes minoritaires IG\_HIGH et SPEC\_LOW présentent des couvertures inférieures à 80\%. Cette hétérogénéité reflète le déséquilibre résiduel malgré le regroupement des classes.
    
    En effet, une claire corrélation entre la taille de la classe et la couverture est observée : les classes avec plus d'observations dans le calibration set bénéficient de meilleures estimations des scores de conformité, conduisant à des ensembles plus précis. 

    \subsubsection*{Interprétation métier}
    
    La prédiction conforme en classification apporte une valeur décisionnelle claire. Un ensemble singleton \{IG\_MED\} signale une entreprise clairement identifiée comme Investment Grade de qualité moyenne, autorisant une décision rapide. Un ensemble \{IG\_LOW, SPEC\_HIGH\} révèle une entreprise à la frontière critique BBB/BB, justifiant une analyse approfondie avant décision. Un ensemble large \{IG\_MED, IG\_LOW, SPEC\_HIGH\} indique une forte incertitude nécessitant une due diligence complète.
    
    Dans le contexte réglementaire de Bâle III, cette information est précieuse afin de pouvoir justifier les décisions d'investissement auprès des régulateurs.
    
    \subsubsection*{Limites et perspectives}
    
    Le principal frein observé est la taille limitée du dataset (2~031 obs.), conduisant à un calibration set de seulement 609 observations pour SCP. Cette contrainte explique les couvertures sous-optimales (87.68\% au lieu de 90\%). Une solution serait d'enrichir le dataset avec davantage d'entreprises notées, ou d'appliquer des techniques d'augmentation de données pour renforcer les classes minoritaires.
    
    \section{Conclusion}

    Ce projet a implémenté et comparé la \textbf{régression quantile} et la \textbf{prédiction conforme} sur deux problématiques financières : l'évaluation du risque de crédit individuel (régression) et la notation d'entreprises (classification).

    Dans le secteur financier, ces techniques apportent trois avantages majeurs : (1) la \textbf{quantification de l'incertitude} permet d'adapter les conditions de prêt selon le profil, (2) les \textbf{garanties statistiques formelles} répondent aux exigences réglementaires de Bâle III, (3) la \textbf{détection automatique des cas ambigus} optimise l'allocation des ressources d'analyse entre traitement automatisé et expertise humaine.

    Les perspectives incluent l'implémentation de Conformal Quantile Regression pour des intervalles adaptatifs, l'enrichissement des datasets et l'exploration de modèles de base plus performants.

    \bibliographystyle{plain}
    \bibliography{references}

\end{document}